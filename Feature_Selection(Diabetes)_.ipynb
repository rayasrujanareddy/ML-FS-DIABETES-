{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP31DiTMb9Im88MJnYpj+Ss",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rayasrujanareddy/ML-FS-DIABETES-/blob/main/Feature_Selection(Diabetes)_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Missing Values Ratio"
      ],
      "metadata": {
        "id": "ETt54U18hxY7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j_alUuDhFQaI",
        "outputId": "92204e7c-20a1-42b5-b2d6-333a8ebb6f87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Features Removed (more than 30% missing): Index([], dtype='object')\n",
            "Dataset Shape after Features Removal: (768, 9)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the diabetes dataset\n",
        "file_path = '/content/diabetes.csv'\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Step 3: Identify and remove features with more than 30% missing values\n",
        "threshold = 30\n",
        "features_to_remove = missing_percentage[missing_percentage > threshold].index\n",
        "\n",
        "# Use 'columns' instead of 'Features' in the drop function\n",
        "reduced_data = data.drop(columns=features_to_remove)\n",
        "\n",
        "print(\"\\nFeatures Removed (more than 30% missing):\", features_to_remove)\n",
        "print(\"Dataset Shape after Features Removal:\", reduced_data.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## High Correlation Filter"
      ],
      "metadata": {
        "id": "6Xo4VqVnkkrM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "# Import numpy\n",
        "import numpy as np # This line imports the numpy library and assigns it to the alias 'np'\n",
        "\n",
        "# Step 1: Compute the correlation matrix\n",
        "correlation_matrix = data.corr()\n",
        "\n",
        "# Step 2: Identify highly correlated feature pairs (correlation > 0.8)\n",
        "threshold = 0.8\n",
        "highly_correlated_pairs = np.where((correlation_matrix > threshold) & (correlation_matrix < 1.0))\n",
        "\n",
        "# Create a set to store features to remove\n",
        "features_to_remove = set()\n",
        "\n",
        "for i, j in zip(*highly_correlated_pairs):\n",
        "    features_to_remove.add(correlation_matrix.columns[j])  # Remove the second feature in the pair\n",
        "\n",
        "# Assuming correlated_features is a variable you want to define based on features_to_remove\n",
        "correlated_features = list(features_to_remove)\n",
        "print(\"Highly Correlated Feature Pairs (correlation > 0.8):\", correlated_features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MWBZcQBji8U0",
        "outputId": "a6172934-d71b-410f-e457-32cf50229d0d"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Highly Correlated Feature Pairs (correlation > 0.8): []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Low Variance Filter\n"
      ],
      "metadata": {
        "id": "TyvKYZbNkswp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import VarianceThreshold\n",
        "import pandas as pd\n",
        "\n",
        "# Step 1: Set the threshold for low variance (e.g., < 0.01)\n",
        "threshold = 0.01\n",
        "var_filter = VarianceThreshold(threshold=threshold)\n",
        "\n",
        "# Step 2: Fit and transform the data\n",
        "X_filtered = var_filter.fit_transform(data.drop('Outcome', axis=1))\n",
        "reduced_data = pd.DataFrame(X_filtered, columns=data.drop('Outcome', axis=1).columns[var_filter.get_support()])\n",
        "\n",
        "# Calculate the variance of each feature\n",
        "variance = var_filter.variances_\n",
        "\n",
        "# Remove features with variance below the threshold\n",
        "low_variance_features = data.drop('Outcome', axis=1).columns[variance < threshold] # Get the feature names\n",
        "reduced_data = data.drop(columns=low_variance_features) # Drop from the original dataframe\n",
        "\n",
        "print(f\"Features removed due to low variance: {low_variance_features}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jZRFzeFFdhZ5",
        "outputId": "fbb17238-d95f-4c8c-b7e8-bd5576cbbeb7"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features removed due to low variance: Index([], dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Forward Feature Selection"
      ],
      "metadata": {
        "id": "V3mMJalnkiEv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.feature_selection import SequentialFeatureSelector\n",
        "\n",
        "# Load the diabetes dataset\n",
        "data = pd.read_csv('/content/diabetes.csv')\n",
        "\n",
        "# Separate features and target variable\n",
        "X = data.drop('Outcome', axis=1)\n",
        "y = data['Outcome']\n",
        "\n",
        "# Step 1: Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 2: Create a Logistic Regression model\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "\n",
        "# Step 3: Apply Forward Feature Selection using SequentialFeatureSelector\n",
        "# Change n_features_to_select to 'auto' instead of None\n",
        "selector = SequentialFeatureSelector(model, direction='forward', n_features_to_select='auto', scoring='accuracy', cv=5)\n",
        "selector = selector.fit(X_train, y_train)\n",
        "\n",
        "# Step 4: Get the selected features\n",
        "selected_features = X_train.columns[selector.get_support()]\n",
        "\n",
        "print(\"Selected Features From Forward Selection:\", selected_features)\n",
        "\n",
        "# Step 5: Train the model using only the selected features\n",
        "X_train_selected = selector.transform(X_train)\n",
        "X_test_selected = selector.transform(X_test)\n",
        "\n",
        "model.fit(X_train_selected, y_train)\n",
        "\n",
        "# Step 6: Predict and calculate accuracy\n",
        "y_pred = model.predict(X_test_selected)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(\"Model Accuracy after Forward Feature Selection:\", accuracy)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xxOChxrpkym2",
        "outputId": "3e9d8519-c9aa-4881-85ea-e12e93b36e05"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected Features From Forward Selection: Index(['Pregnancies', 'Glucose', 'BMI', 'DiabetesPedigreeFunction'], dtype='object')\n",
            "Model Accuracy after Forward Feature Selection: 0.7727272727272727\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Backward Feature Elimination"
      ],
      "metadata": {
        "id": "andgaJblmrJl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.feature_selection import RFE\n",
        "\n",
        "# Load the diabetes dataset\n",
        "data = pd.read_csv('/content/diabetes.csv')\n",
        "\n",
        "# Separate features and target variable\n",
        "X = data.drop('Outcome', axis=1)\n",
        "y = data['Outcome']\n",
        "\n",
        "# Step 1: Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 2: Create a Decision Tree classifier\n",
        "model = DecisionTreeClassifier()\n",
        "\n",
        "# Step 3: Apply Backward Feature Elimination using Recursive Feature Elimination (RFE)\n",
        "# n_features_to_select=None will eliminate features until one is left\n",
        "selector = RFE(model, n_features_to_select=1, step=1)\n",
        "selector = selector.fit(X_train, y_train)\n",
        "\n",
        "# Step 4: Get the ranking of features\n",
        "ranking = selector.ranking_\n",
        "selected_features = X_train.columns[selector.support_]\n",
        "\n",
        "print(\"Selected Features after Backward Elimination:\", selected_features)\n",
        "\n",
        "# Step 5: Train the model using only the selected features\n",
        "X_train_selected = selector.transform(X_train)\n",
        "X_test_selected = selector.transform(X_test)\n",
        "\n",
        "model.fit(X_train_selected, y_train)\n",
        "\n",
        "# Step 6: Predict and calculate accuracy\n",
        "y_pred = model.predict(X_test_selected)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(\"Model Accuracy after Backward Feature Elimination:\", accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AqOmMtc3oH3X",
        "outputId": "54b33d88-9fb7-4c17-e50a-afb828010188"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected Features after Backward Elimination: Index(['Glucose'], dtype='object')\n",
            "Model Accuracy after Backward Feature Elimination: 0.6688311688311688\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Random Forest"
      ],
      "metadata": {
        "id": "iWtWM-yoo9dx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the diabetes dataset\n",
        "data = pd.read_csv('/content/diabetes.csv')\n",
        "\n",
        "# Step 1: Separate features and target variable\n",
        "X = data.drop('Outcome', axis=1)\n",
        "y = data['Outcome']\n",
        "\n",
        "# Step 2: Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 3: Train a Random Forest model\n",
        "rf_model = RandomForestClassifier(random_state=42)\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# Step 4: Get feature importances from the trained Random Forest model\n",
        "feature_importances = rf_model.feature_importances_\n",
        "\n",
        "# Step 5: Rank the features based on importance\n",
        "feature_ranking = pd.Series(feature_importances, index=X.columns).sort_values(ascending=False)\n",
        "print(\"Feature importance ranking:\\n\", feature_ranking)\n",
        "\n",
        "# Step 6: Keep only the top 5 most important features\n",
        "top_5_features = feature_ranking.index[:5]\n",
        "X_train_reduced = X_train[top_5_features]\n",
        "X_test_reduced = X_test[top_5_features]\n",
        "\n",
        "# Step 7: Train a new Random Forest model on the reduced feature set\n",
        "rf_model_reduced = RandomForestClassifier(random_state=42)\n",
        "rf_model_reduced.fit(X_train_reduced, y_train)\n",
        "\n",
        "# Step 8: Predict and calculate accuracy using the reduced feature set\n",
        "y_pred_reduced = rf_model_reduced.predict(X_test_reduced)\n",
        "accuracy_reduced = accuracy_score(y_test, y_pred_reduced)\n",
        "\n",
        "print(\"Model accuracy with top 5 features:\", accuracy_reduced)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4UY5r8qAo94m",
        "outputId": "498eedec-7654-4202-dc92-c96e0e78eb58"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature importance ranking:\n",
            " Glucose                     0.258864\n",
            "BMI                         0.169984\n",
            "Age                         0.140931\n",
            "DiabetesPedigreeFunction    0.123768\n",
            "BloodPressure               0.088134\n",
            "Pregnancies                 0.076551\n",
            "Insulin                     0.076122\n",
            "SkinThickness               0.065646\n",
            "dtype: float64\n",
            "Model accuracy with top 5 features: 0.7792207792207793\n"
          ]
        }
      ]
    }
  ]
}